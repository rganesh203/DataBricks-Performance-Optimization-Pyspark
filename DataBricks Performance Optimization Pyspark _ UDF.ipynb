{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1b45c5a-5baf-4d75-a6dd-1477b8377836",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "User Defined Functions (UDFs) in PySpark allow you to define custom functions for use in DataFrame operations. However, UDFs can introduce performance overhead because they require serialization and deserialization of data between the JVM and Python. To mitigate this, it’s important to optimize the use of UDFs and prefer built-in functions whenever possible.\n",
    "\n",
    "Here’s how to optimize UDFs in PySpark with an example:%md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9903ee6d-55b1-4ba6-bbc7-17d235717d24",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Best Practices for Optimizing UDFs\n",
    "\n",
    "Use Built-in Functions When Possible: PySpark's built-in functions are highly optimized and should be preferred over UDFs.\n",
    "\n",
    "Pandas UDFs (Vectorized UDFs): Use Pandas UDFs for better performance, as they process data in batches and can leverage Apache Arrow for efficient data interchange.\n",
    "\n",
    "Broadcast Variables: Use broadcast variables to efficiently send large read-only data to all nodes.\n",
    "\n",
    "Minimize UDF Usage: Only use UDFs when necessary and keep them as simple as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e8f9714-a267-4f6a-8f2b-77a245211239",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Example of Using UDFs in PySpark\n",
    "\n",
    "Standard UDF\n",
    "\n",
    "Define and Register UDF: Define a simple UDF that adds a constant value to a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ab54339-4618-488f-ab14-b9ca9049b192",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col1</th><th>col2</th><th>col3</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>3</td></tr><tr><td>2</td><td>3</td><td>4</td></tr><tr><td>3</td><td>4</td><td>5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         2,
         3
        ],
        [
         2,
         3,
         4
        ],
        [
         3,
         4,
         5
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col1",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "col2",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "col3",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"UDF Optimization Example\").getOrCreate()\n",
    "\n",
    "# Sample DataFrame\n",
    "data = [(1, 2), (2, 3), (3, 4)]\n",
    "df = spark.createDataFrame(data, [\"col1\", \"col2\"])\n",
    "\n",
    "# Define UDF\n",
    "def add_one(x):\n",
    "    return x + 1\n",
    "\n",
    "add_one_udf = udf(add_one, IntegerType())\n",
    "\n",
    "# Register and Apply UDF\n",
    "df = df.withColumn(\"col3\", add_one_udf(df.col2))\n",
    "df.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1ef72b0-8372-466f-99f7-e30ddc920386",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Pandas UDF (Vectorized UDF)\n",
    "\n",
    "Define and Use Pandas UDF: Use a Pandas UDF for better performance, especially with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42027069-7d4a-4477-8ec3-4ef2e614d7ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col1</th><th>col2</th><th>col3</th><th>col4</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>3</td><td>3</td></tr><tr><td>2</td><td>3</td><td>4</td><td>4</td></tr><tr><td>3</td><td>4</td><td>5</td><td>5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         2,
         3,
         3
        ],
        [
         2,
         3,
         4,
         4
        ],
        [
         3,
         4,
         5,
         5
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col1",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "col2",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "col3",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "col4",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pandas as pd\n",
    "\n",
    "# Define Pandas UDF\n",
    "@pandas_udf(IntegerType())\n",
    "def add_one_pandas_udf(x: pd.Series) -> pd.Series:\n",
    "    return x + 1\n",
    "\n",
    "# Apply Pandas UDF\n",
    "df = df.withColumn(\"col4\", add_one_pandas_udf(df.col2))\n",
    "df.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb6791f4-5b80-461d-80da-ace5b0366d59",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Using Built-in Functions (Preferred)\n",
    "Replace UDF with Built-in Functions: Whenever possible, use built-in functions for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ab9ebb7-4f86-4712-b571-b2ddd8218357",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col1</th><th>col2</th><th>col3</th><th>col4</th><th>col5</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>3</td><td>3</td><td>3</td></tr><tr><td>2</td><td>3</td><td>4</td><td>4</td><td>4</td></tr><tr><td>3</td><td>4</td><td>5</td><td>5</td><td>5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         2,
         3,
         3,
         3
        ],
        [
         2,
         3,
         4,
         4,
         4
        ],
        [
         3,
         4,
         5,
         5,
         5
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col1",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "col2",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "col3",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "col4",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "col5",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Use Built-in Function\n",
    "df = df.withColumn(\"col5\", col(\"col2\") + 1)\n",
    "df.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5f5f06a-c5c5-4dc3-8160-7da3ce59db0d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Summary\n",
    "\n",
    "Prefer Built-in Functions: Always try to use PySpark’s built-in functions for performance-critical operations.\n",
    "\n",
    "Use Pandas UDFs: When custom functions are necessary, use Pandas UDFs for better performance.\n",
    "\n",
    "Minimize UDFs: Keep UDF usage to a minimum and avoid complex logic inside UDFs.\n",
    "\n",
    "Broadcast Variables: Utilize broadcast variables to handle large read-only datasets efficiently.\n",
    "\n",
    "By following these best practices, you can optimize your PySpark jobs and improve overall performance in Databricks."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataBricks Performance Optimization Pyspark | UDF",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
