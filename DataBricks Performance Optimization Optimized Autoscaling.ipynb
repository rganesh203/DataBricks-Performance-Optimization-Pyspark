{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fae14fb6-da88-4ccc-b299-549e4ee080ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Optimized autoscaling in Databricks is a feature that automatically adjusts the number of active nodes in a cluster based on the workload, ensuring efficient use of resources and maintaining performance. This helps in reducing costs by scaling down when the demand is low and scaling up when the demand is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a206a0-8aaf-46fc-a594-a43a4f2d124a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Key Features of Optimized Autoscaling\n",
    "\n",
    "Proactive Scaling: Adds nodes proactively before a resource bottleneck occurs.\n",
    "\n",
    "Lazy Termination: Keeps nodes running longer to handle potential spikes in workload.\n",
    "\n",
    "Dynamic Scaling: Adjusts the number of nodes based on both job queue size and the stage of the jobs.\n",
    "\n",
    "Instance Pools: Reuses instances from a pool to reduce startup times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ced96b0-ef5a-4f16-9bb2-03e6a7554dfb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "How Optimized Autoscaling Works\n",
    "\n",
    "Monitoring: Continuously monitors the workload and resource utilization.\n",
    "\n",
    "Scaling Up: When it detects increased demand (e.g., long job queue or high CPU/memory utilization), it adds nodes.\n",
    "\n",
    "Scaling Down: When the demand decreases, it removes idle nodes to save costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96de6daf-95c1-4ae1-9fde-d7e0f1474795",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Example of Optimized Autoscaling in Databricks\n",
    "Let's go through an example of setting up a Databricks cluster with optimized autoscaling.\n",
    "\n",
    "Step 1: Create a Cluster\n",
    "\n",
    "Navigate to the Databricks workspace.\n",
    "\n",
    "Click on the \"Clusters\" tab.\n",
    "\n",
    "Click \"Create Cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7db498c1-cde1-4a71-91de-4f9fbca951ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Step 2: Configure Cluster Settings\n",
    "Cluster Name: Enter a name for your cluster.\n",
    "\n",
    "Cluster Mode: Select Standard or High Concurrency based on your use case.\n",
    "\n",
    "Databricks Runtime Version: Choose an appropriate runtime version.\n",
    "\n",
    "Autoscaling: Enable autoscaling by checking the Enable autoscaling option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "908deae1-cbf9-4360-8d64-f17f8aef201e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Step 3: Set Worker Configuration\n",
    "\n",
    "Min Workers: Set the minimum number of worker nodes (e.g., 2).\n",
    "\n",
    "Max Workers: Set the maximum number of worker nodes (e.g., 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d3e65cd-252a-4676-8614-65645c28d563",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Step 4: Instance Type\n",
    "\n",
    "Worker Type: Select an instance type for the workers (e.g., r5.xlarge).\n",
    "\n",
    "Driver Type: Select an instance type for the driver (e.g., r5.xlarge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8eef3b20-b119-4ccf-aa43-f17b75a2e636",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Step 5: Advanced Options (Optional)\n",
    "\n",
    "Spot Instances: Enable spot instances to reduce costs if your workloads can tolerate interruptions.\n",
    "\n",
    "Instance Pools: Use instance pools to reduce startup times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f286b67-67de-436b-be6d-76917b446ae7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Example Python Code to Submit Jobs to the Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98305002-e9d2-46e0-9fc7-bfd8d7b0f188",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ExampleApp\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample DataFrame creation\n",
    "data = [(\"John\", 30), (\"Doe\", 25), (\"Jane\", 28)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "# Perform some operations\n",
    "df_filtered = df.filter(df.Age > 25)\n",
    "df_filtered.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ef823e1-30f4-433b-99d5-eb4ba508cdc4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Monitor and Optimize\n",
    "\n",
    "Monitor Cluster Performance: Use the Databricks UI to monitor cluster performance and scaling events.\n",
    "\n",
    "Adjust Settings: Based on the workload and performance metrics, adjust the min and max worker settings as needed.\n",
    "\n",
    "Instance Pools: If not already configured, consider setting up instance pools for frequently used instance types to reduce startup latency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc979f66-a037-4ad2-822e-dc4adeab0086",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Best Practices for Optimized Autoscaling\n",
    "Set Appropriate Min and Max Workers: Choose the min and max values based on the typical workload to ensure scalability while controlling costs.\n",
    "\n",
    "Monitor Usage: Regularly monitor the cluster's performance and utilization to adjust the autoscaling settings.\n",
    "\n",
    "Use Instance Pools: Preconfigure instance pools for faster scaling, especially if your workloads require quick startup times.\n",
    "\n",
    "Spot Instances: Leverage spot instances for non-critical workloads to reduce costs.\n",
    "\n",
    "\n",
    "By following these steps and best practices, you can effectively use optimized autoscaling in Databricks to manage your cluster resources dynamically, ensuring performance and cost-efficiency."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataBricks Performance Optimization Optimized Autoscaling",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
