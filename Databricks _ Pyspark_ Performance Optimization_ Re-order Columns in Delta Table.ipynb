{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "546f0754-7eb1-470d-bdc4-5267e62554fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Reordering columns in a Delta table using PySpark in Databricks can be necessary for optimizing performance, especially when you want to improve query efficiency by placing frequently accessed columns together or reducing the amount of data scanned for certain operations. Here’s an example of how you can achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d722496a-49de-42b5-897f-b34619567ac0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th></tr></thead><tbody><tr><td>1</td><td>John</td></tr><tr><td>3</td><td>Doe</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "John"
        ],
        [
         3,
         "Doe"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Delta Lake Column Reordering Example\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Example Delta table path\n",
    "delta_table_path = \"/delta-table\"\n",
    "\n",
    "# Read Delta table\n",
    "delta_df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "\n",
    "# Define new column order (example: move 'name' column before 'id')\n",
    "new_column_order = ['name', 'id'] + [col for col in delta_df.columns if col not in ['name', 'id']]\n",
    "\n",
    "# Reorder columns in DataFrame\n",
    "reordered_df = delta_df.select(*new_column_order)\n",
    "\n",
    "# Overwrite Delta table with reordered DataFrame\n",
    "reordered_df.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
    "\n",
    "# Optionally, optimize table to ensure performance improvements are applied\n",
    "DeltaTable.forPath(spark, delta_table_path).optimize()\n",
    "\n",
    "# Read the Delta table after reordering\n",
    "delta_df_after_reorder = spark.read.format(\"delta\").load(delta_table_path)\n",
    "delta_df_after_reorder.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98999bd1-f12f-4df7-9223-e12227920ce7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Explanation:\n",
    "Initialize Spark Session: Start the Spark session with necessary configurations for Delta Lake.\n",
    "\n",
    "Read Delta Table: Use DeltaTable.forPath() to access the Delta table located at delta_table_path.\n",
    "\n",
    "Get Current Schema: Retrieve the current schema of the Delta table using delta_table.schema().\n",
    "\n",
    "Define New Column Order: Specify the new order of columns as needed. This example moves the column 'name' before 'id'.\n",
    "\n",
    "Reorder Columns: Load the Delta table into a DataFrame (reordered_df) and select columns in the desired order using .select(*new_column_order).\n",
    "\n",
    "Overwrite Delta Table: Write the reordered DataFrame back to the Delta table using .write.format(\"delta\").mode(\"overwrite\").save(delta_table_path).\n",
    "\n",
    "Optimize Table: Optionally, call delta_table.optimize() to optimize the Delta table, which can include tasks like data skipping and file compaction for improved query performance.\n",
    "\n",
    "Verify: Finally, read and display the Delta table (delta_df) to verify that the columns have been reordered as expected.\n",
    "\n",
    "This process ensures that the Delta table’s columns are reordered efficiently while leveraging Delta Lake’s transactional capabilities to maintain data integrity and performance. Adjust the new_column_order list as per your specific requirements to optimize query performance based on access patterns and data usage."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks | Pyspark| Performance Optimization: Re-order Columns in Delta Table",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
