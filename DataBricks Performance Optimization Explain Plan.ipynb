{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a9609a3-2b5e-45ae-8a18-c991671c545b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "In Databricks, the EXPLAIN command is a powerful tool to understand the execution plan of a query. This helps in identifying performance bottlenecks and optimizing queries. Hereâ€™s an example of how to use EXPLAIN for performance optimization in Databricks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4042eebc-1a21-42d1-ac26-15c1fd41f72d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Example Scenario\n",
    "Assume you have a Delta Lake table called sales and you want to optimize a query that aggregates sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80bc9d4f-b7fa-4786-8d7b-983ce5cae772",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Step-by-Step Guide\n",
    "1. Analyze the Execution Plan\n",
    "First, let's write a query to analyze the total sales by product category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40ebe235-139a-498b-aadb-3effc47d5b8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"DatabricksPerformanceOptimization\").getOrCreate()\n",
    "\n",
    "sales_df = spark.read.format(\"delta\").load(\"/path/to/sales\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT product_category, SUM(sales_amount) as total_sales\n",
    "FROM sales\n",
    "GROUP BY product_category\n",
    "\"\"\"\n",
    "\n",
    "sales_df.createOrReplaceTempView(\"sales\")\n",
    "result = spark.sql(query)\n",
    "result.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9cbe175-bac8-4647-bebd-a8609445a024",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "To understand the execution plan of this query, use the EXPLAIN statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0aa9afd8-4e28-4019-a782-56441a7ff20d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "explain_query = \"\"\"\n",
    "EXPLAIN\n",
    "SELECT product_category, SUM(sales_amount) as total_sales\n",
    "FROM sales\n",
    "GROUP BY product_category\n",
    "\"\"\"\n",
    "\n",
    "explain_result = spark.sql(explain_query)\n",
    "explain_result.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04f983c4-ad4e-4b28-a860-2c389d1c5a10",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "2. Interpret the Execution Plan\n",
    "The execution plan will display information about how Spark plans to execute the query. Key parts of the plan to pay attention to include:\n",
    "\n",
    "Logical Plan: The abstract representation of the query.\n",
    "Physical Plan: The detailed execution strategy including operations like scans, joins, and aggregations.\n",
    "Exchange: Indicates a data shuffle which can be expensive.\n",
    "Aggregation: Shows how data aggregation is performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99cc4b19-b812-4675-9cda-69391ea3e87e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "3. Identify Bottlenecks\n",
    "Look for operations that might be causing performance issues:\n",
    "\n",
    "Shuffles: Data movement across the cluster, which is expensive.\n",
    "Skew: Uneven distribution of data can lead to some tasks taking much longer than others.\n",
    "Spills: Operations that exceed memory limits and spill to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f44356d1-a039-4082-bb4d-fd3a0e2144d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "4. Optimize the Query\n",
    "Based on the insights from the execution plan, apply optimization techniques:\n",
    "\n",
    "Repartitioning: Optimize the distribution of data to reduce shuffles.\n",
    "Broadcast Joins: For smaller tables, use broadcast joins to avoid shuffles.\n",
    "Caching: Cache intermediate DataFrames to avoid recomputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03c5cedd-54ba-428d-b34d-17518dba1b5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "5. Re-run the Query with Optimizations\n",
    "Apply optimizations and re-run the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3edc2f2-2d1b-422c-a505-bbcbc05ee3bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Repartitioning\n",
    "sales_df = sales_df.repartition(\"product_category\")\n",
    "\n",
    "# Run the optimized query\n",
    "optimized_query = \"\"\"\n",
    "SELECT product_category, SUM(sales_amount) as total_sales\n",
    "FROM sales\n",
    "GROUP BY product_category\n",
    "\"\"\"\n",
    "\n",
    "optimized_result = spark.sql(optimized_query)\n",
    "optimized_result.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1429f174-e0e6-4ae4-9acc-a5437b9a671e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Example of Optimized Execution Plan\n",
    "After applying optimizations, generate and analyze the new execution plan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d21425d5-04f6-4afb-bf9e-145886a7f09e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optimized_explain_query = \"\"\"\n",
    "EXPLAIN\n",
    "SELECT product_category, SUM(sales_amount) as total_sales\n",
    "FROM sales\n",
    "GROUP BY product_category\n",
    "\"\"\"\n",
    "\n",
    "optimized_explain_result = spark.sql(optimized_explain_query)\n",
    "optimized_explain_result.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2e11278-5640-4260-b3bf-dcf0264bfa7c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Summary\n",
    "\n",
    "Initial Query Analysis: Use EXPLAIN to understand the initial execution plan.\n",
    "\n",
    "Bottleneck Identification: Identify operations like shuffles and skew in the execution plan.\n",
    "\n",
    "Optimization Techniques: Apply techniques such as repartitioning, broadcast joins, and caching.\n",
    "\n",
    "Re-evaluation: Re-run the optimized query and compare the new execution plan.\n",
    "\n",
    "By iteratively using the EXPLAIN command and applying targeted optimizations, you can significantly improve the performance of your queries in Databricks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataBricks Performance Optimization Explain Plan",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
