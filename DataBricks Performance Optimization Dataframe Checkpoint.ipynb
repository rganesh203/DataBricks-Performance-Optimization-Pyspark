{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4fc2cce-8f5b-4de7-8cbf-934b1a927d98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Checkpointing is a technique used in Databricks to optimize the performance of DataFrame operations by saving intermediate states to disk. This can help in cases where you have complex transformations and want to avoid recomputing the same operations in case of job failures or for iterative algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bab391e0-ecaf-48b9-a864-c29781439b05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Benefits of Checkpointing\n",
    "Fault Tolerance: Provides a way to recover from failures without recomputing the entire transformation pipeline.\n",
    "Performance: Saves the state of a DataFrame to disk, reducing the need to recompute intermediate steps and speeding up iterative algorithms.\n",
    "Debugging: Allows you to inspect the state of your DataFrame at different stages of your transformation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54f97e1b-7cce-4560-bfb1-b35ab3b351d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "How to Use Checkpointing in Databricks\n",
    "To use checkpointing, you need to enable checkpointing directory and then call checkpoint() on your DataFrame. Hereâ€™s a step-by-step example:\n",
    "\n",
    "Step 1: Enable Checkpointing Directory\n",
    "Set the checkpoint directory in your Spark configuration. This should be done before any checkpoint operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d51e2c81-c7cb-43ab-acd7-4a685546e7ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir(\"/tmp/checkpoints\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9da41c5a-a0f5-41bf-9def-08816a948667",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Step 2: Create a DataFrame and Perform Transformations\n",
    "Create a DataFrame and perform some transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c510522-b7bc-491d-bc1e-000e55e6aa53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CheckpointExample\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(\"Alice\", 34), (\"Bob\", 45), (\"Catherine\", 29), (\"David\", 40)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "\n",
    "# Perform some transformations\n",
    "df_transformed = df.withColumn(\"Age_plus_10\", col(\"Age\") + 10)\n",
    "df_transformed.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38869b8c-faf9-4c26-b48d-84665a408b17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Step 3: Checkpoint the DataFrame\n",
    "Checkpoint the DataFrame after performing transformations. This saves the current state of the DataFrame to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcedba80-ccf0-48d0-a232-9d5483eb2ffe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_transformed.checkpoint()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99529b72-faca-4038-b3a9-9ae971ea446c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Step 4: Further Transformations and Actions\n",
    "You can continue to perform more transformations and actions on the checkpointed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a81b2938-0b9a-465b-a1d4-2eb120b8e5e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final = df_transformed.withColumn(\"Age_double\", col(\"Age_plus_10\") * 2)\n",
    "df_final.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08cb8005-8da9-4576-ba30-10d75256cf53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Tips for Using Checkpointing\n",
    "\n",
    "Frequency: Use checkpointing judiciously. Overuse can lead to excessive disk I/O and increased storage costs.\n",
    "\n",
    "Storage: Ensure your checkpoint directory has sufficient storage and is in a location that supports high I/O operations.\n",
    "\n",
    "Placement: Place checkpoints at logical points in your transformation pipeline, especially before iterative operations or after expensive computations.\n",
    "\n",
    "By using checkpointing effectively, you can significantly improve the performance and reliability of your data processing pipelines in Databricks."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataBricks Performance Optimization Dataframe Checkpoint",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
